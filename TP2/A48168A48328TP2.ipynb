{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://2223moodle.isel.pt/pluginfile.php/1/theme_adaptable/logo/1631635830/logo-isel_inv3.png\" width=\"250\">\n",
    "<h3>Licenciatura em Engenharia Informática e Multimédia</h3><br>\n",
    "<br>\n",
    "<h2>Aprendizagem Automática (AA)</h3>\n",
    "<h3>2º Trabalho Laboratorial – Classificação de Críticas de Cinema do IMDb </h3>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "Trabalho Realizado por:<br>\n",
    "Gonçalo Silva <b>A48328</b><br>\n",
    "Diogo Lobo <b>A48168</b><br>\n",
    "Turma 52D<br><br>\n",
    "Docente: Gonçalo Xufre <br>\n",
    "<br>\n",
    "9 de Dezembro de 2024\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 129,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 130,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pickle.load(open('imdbFull.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 131,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset contains movie reviews along with their associated binary sentiment polarity labels. It is intended to serve as a benchmark for sentiment classification. This document outlines how the dataset was gathered, and how to use the files provided.\n",
      "For more details see: http://ai.stanford.edu/~amaas/data/sentiment/\n",
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "Docs = D.data\n",
    "y = D.target\n",
    "descr = D.DESCR\n",
    "print(descr)\n",
    "print(len(Docs))\n",
    "print(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 132,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import PorterStemmer,SnowballStemmer,LancasterStemmer\n",
    "\n",
    "# porterStemFunc = PorterStemmer()\n",
    "# Docs_PorterStem = [' '.join([porterStemFunc.stem(word) for word in doc.split()]) for doc in Docs]\n",
    "# pickle.dump(Docs_PorterStem,open('docsPorterStem.p','wb'))\n",
    "\n",
    "# snowballSteamFunc = SnowballStemmer('english')\n",
    "# Docs_SnowballStem = [' '.join([snowballSteamFunc.stem(word) for word in doc.split()]) for doc in Docs]\n",
    "# pickle.dump(Docs_SnowballStem,open('docsSnowballStem.p','wb'))\n",
    "\n",
    "# lancasterStemFunc = LancasterStemmer()\n",
    "# Docs_LancasterStem = [' '.join([lancasterStemFunc.stem(word) for word in doc.split()]) for doc in Docs]\n",
    "# pickle.dump(Docs_PorterStem,open('docsLancasterStem.p','wb'))\n",
    "\n",
    "# print(Docs_PorterStem[0])\n",
    "# print(Docs_SnowballStem[0])\n",
    "# print(Docs_LancasterStem[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 133,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero day lead you to think, even re-think whi two boys/young men would do what they did - commit mutual suicid via slaughter their classmates. it captur what must be beyond a bizarr mode of be for two human who have decid to withdraw from common civil in order to defin their own/mutu world via coupl destruction.<br /><br />it is not a perfect movi but given what money/tim the filmmak and actor had - it is a remark product. in term of explain the motiv and action of the two young suicide/murder it is better than 'elephant' - in term of be a film that get under our 'rationalistic' skin it is a far, far better film than almost anyth you are like to see. <br /><br />flaw but honest with a terribl honesty.\n",
      "zero day lead you to think, even re-think whi two boys/young men would do what they did - commit mutual suicid via slaughter their classmates. it captur what must be beyond a bizarr mode of be for two human who have decid to withdraw from common civil in order to defin their own/mutu world via coupl destruction.<br /><br />it is not a perfect movi but given what money/tim the filmmak and actor had - it is a remark product. in term of explain the motiv and action of the two young suicide/murder it is better than 'elephant' - in term of be a film that get under our 'rationalistic' skin it is a far, far better film than almost anyth you are like to see. <br /><br />flaw but honest with a terribl honesty.\n",
      "zero day lead you to think, even re-think whi two boys/young men would do what they did - commit mutual suicid via slaughter their classmates. it captur what must be beyond a bizarr mode of be for two human who have decid to withdraw from common civil in order to defin their own/mutu world via coupl destruction.<br /><br />it is not a perfect movi but given what money/tim the filmmak and actor had - it is a remark product. in term of explain the motiv and action of the two young suicide/murder it is better than 'elephant' - in term of be a film that get under our 'rationalistic' skin it is a far, far better film than almost anyth you are like to see. <br /><br />flaw but honest with a terribl honesty.\n"
     ]
    }
   ],
   "source": [
    "DocsPorterStem = pickle.load(open('docsPorterStem.p','rb'))\n",
    "DocsSnowballStem = pickle.load(open('docsPorterStem.p','rb'))\n",
    "DocsLancasterStem = pickle.load(open('docsPorterStem.p','rb'))\n",
    "\n",
    "print(DocsPorterStem[0])\n",
    "print(DocsSnowballStem[0])\n",
    "print(DocsLancasterStem[0])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 134,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero day lead you to think, even re-think whi two boys/young men would do what they did - commit mutual suicid via slaughter their classmates. it captur what must be beyond a bizarr mode of be for two human who have decid to withdraw from common civil in order to defin their own/mutu world via coupl destruction.<br /><br />it is not a perfect movi but given what money/tim the filmmak and actor had - it is a remark product. in term of explain the motiv and action of the two young suicide/murder it is better than 'elephant' - in term of be a film that get under our 'rationalistic' skin it is a far, far better film than almost anyth you are like to see. <br /><br />flaw but honest with a terribl honesty.\n",
      "zero day lead you to think even re-think whi two boys young men would do what they did - commit mutual suicid via slaughter their classmates it captur what must be beyond a bizarr mode of be for two human who have decid to withdraw from common civil in order to defin their own mutu world via coupl destruction br br it is not a perfect movi but given what money tim the filmmak and actor had - it is a remark product in term of explain the motiv and action of the two young suicide murder it is better than elephant - in term of be a film that get under our rationalistic skin it is a far far better film than almost anyth you are like to see br br flaw but honest with a terribl honesty \n"
     ]
    }
   ],
   "source": [
    "print(DocsLancasterStem[0])\n",
    "Docs =[re.sub(r'[^a-z-A-Z\\u00c0-\\u00FF]+',' ',doc)for doc in DocsLancasterStem]\n",
    "print(Docs[0])\n",
    "Tfidf = TfidfVectorizer(min_df=10,token_pattern=r'\\b\\w\\w+\\b').fit(Docs)\n",
    "X = Tfidf.transform(Docs)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocsTrain, DocsTest, ytrain, ytest = train_test_split(X,y,test_size=0.50,shuffle=False,random_state=18)\n",
    "DocsValTrain, DocsValTest, yValTrain, yValTest = train_test_split(DocsTrain,ytrain,test_size=0.2,random_state=18,shuffle=False)"
=======
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocsTrain, DocsTest, ytrain, ytest = train_test_split(X,y,test_size=0.50,shuffle=False,random_state=18)"
>>>>>>> parent of 20cfeb8b (TP2)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 136,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "0.6862\n",
      "0.4272\n"
=======
      "Melhores parametros:  {'C': 1, 'max_iter': 1000, 'solver': 'newton-cg', 'tol': 0.001}\n",
      "0.65416\n",
      "0.42328\n"
>>>>>>> parent of 20cfeb8b (TP2)
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "LogReg = LogisticRegression(penalty='l2',C=1,max_iter=1000,tol=0.0001,solver='lbfgs',random_state=18)\n",
    "LogReg.fit(DocsValTrain,yValTrain)\n",
    "print(LogReg.score(DocsValTrain,yValTrain))\n",
    "print(LogReg.score(DocsValTest,yValTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66936\n",
      "0.4214\n"
     ]
    }
   ],
   "source": [
    "LogReg.fit(DocsTrain,ytrain)\n",
    "print(LogReg.score(DocsTrain,ytrain))\n",
    "print(LogReg.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score treino:  0.668\n",
      "Score teste:  0.4266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(C=.1,max_iter=1000,dual=False,fit_intercept=False,penalty='l2',loss='squared_hinge',class_weight=None,random_state=18)\n",
    "\n",
    "svc.fit(DocsValTrain, yValTrain)\n",
    "\n",
    "print('Score treino: ', svc.score(DocsValTrain, yValTrain))\n",
    "print('Score teste: ', svc.score(DocsValTest,yValTest))   "
=======
    "param_grid = {\n",
    "    'C': [0.1, 1, 10,100],\n",
    "    'max_iter': [1000],\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'solver': ['lbfgs', 'saga','newton-cg']\n",
    "}\n",
    "gridSearch = GridSearchCV(LogisticRegression(penalty='l2'),param_grid,cv=5)\n",
    "gridSearch.fit(DocsTrain,ytrain)\n",
    "bestLogReg = gridSearch.best_estimator_\n",
    "print('Melhores parametros: ',gridSearch.best_params_)\n",
    "\n",
    "print(bestLogReg.score(DocsTrain,ytrain))\n",
    "print(bestLogReg.score(DocsTest,ytest))"
>>>>>>> parent of 20cfeb8b (TP2)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65636\n",
      "0.42292\n"
     ]
    }
   ],
   "source": [
    "svc.fit(DocsTrain,ytrain)\n",
    "print(svc.score(DocsTrain,ytrain))\n",
    "print(svc.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7303949079062417\n",
      "0.6176169987047675\n"
     ]
    }
   ],
   "source": [
    "linearSVR =LinearSVR(C=1.0,dual=True,epsilon=0.5,loss='epsilon_insensitive',max_iter=2000,random_state=18)\n",
    "linearSVR.fit(DocsValTrain,yValTrain)\n",
    "print(linearSVR.score(DocsValTrain,yValTrain))\n",
    "print(linearSVR.score(DocsValTest,yValTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7280104929754037\n",
      "0.6009610094561642\n"
     ]
    }
   ],
   "source": [
    "linearSVR.fit(DocsTrain,ytrain)\n",
    "print(linearSVR.score(DocsTrain,ytrain))\n",
    "print(linearSVR.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docs =[re.sub(r'[^a-z-A-Z\\u00c0-\\u00FF]+',' ',doc)for doc in DocsPorterStem]\n",
    "Tfidf = TfidfVectorizer(ngram_range=(1,2),min_df=10,token_pattern=r'\\b\\w\\w+\\b').fit(Docs)\n",
    "# Tfidf = TfidfVectorizer(min_df=10,token_pattern=r'\\b\\w\\w+\\b').fit(Docs)\n",
    "X = Tfidf.transform(Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocsTrain, DocsTest, ytrain, ytest = train_test_split(X,y,test_size=0.50,shuffle=False,random_state=18)\n",
    "DocsValTrain, DocsValTest, yValTrain, yValTest = train_test_split(DocsTrain,ytrain,test_size=0.2,random_state=18,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8066\n",
      "0.4332\n"
     ]
    }
   ],
   "source": [
    "LogReg = LogisticRegression(penalty='l2',C=1,max_iter=1000,tol=0.0001,solver='lbfgs',random_state=18)\n",
    "LogReg.fit(DocsValTrain,yValTrain)\n",
    "print(LogReg.score(DocsValTrain,yValTrain))\n",
    "print(LogReg.score(DocsValTest,yValTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79852\n",
      "0.43472\n"
     ]
    }
   ],
   "source": [
    "LogReg.fit(DocsTrain,ytrain)\n",
    "print(LogReg.score(DocsTrain,ytrain))\n",
    "print(LogReg.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score treino:  0.79975\n",
      "Score teste:  0.426\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(C=.1,max_iter=1000,dual=False,fit_intercept=False,penalty='l2',loss='squared_hinge',class_weight=None,random_state=18)\n",
    "\n",
    "svc.fit(DocsValTrain, yValTrain)\n",
    "\n",
    "print('Score treino: ', svc.score(DocsValTrain, yValTrain))\n",
    "print('Score teste: ', svc.score(DocsValTest,yValTest))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78788\n",
      "0.43492\n"
     ]
    }
   ],
   "source": [
    "svc.fit(DocsTrain,ytrain)\n",
    "print(svc.score(DocsTrain,ytrain))\n",
    "print(svc.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8019934543374861\n",
      "0.6386051036237654\n"
     ]
    }
   ],
   "source": [
    "linearSVR =LinearSVR(C=1.0,dual=True,epsilon=0.5,loss='epsilon_insensitive',max_iter=2000,random_state=18)\n",
    "linearSVR.fit(DocsValTrain,yValTrain)\n",
    "print(linearSVR.score(DocsValTrain,yValTrain))\n",
    "print(linearSVR.score(DocsValTest,yValTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8034966235584976\n",
      "0.6350319555266827\n"
     ]
    }
   ],
   "source": [
    "linearSVR.fit(DocsTrain,ytrain)\n",
    "print(linearSVR.score(DocsTrain,ytrain))\n",
    "print(linearSVR.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linearSVR = LinearSVR(random_state=18)\n",
    "# param_grid = {\n",
    "#     'epsilon': [0.01, 0.1, 0.2, 0.5, 1.0],\n",
    "#     'C': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "#     'max_iter': [1000, 5000, 10000, 20000],\n",
    "#     'loss': ['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "#     'dual': [True, False]\n",
    "# }\n",
    "# gridSVR = GridSearchCV(linearSVR,param_grid=param_grid,cv=5)\n",
    "# gridSVR.fit(DocsTrain,ytrain)\n",
    "\n",
    "# bestSVR = gridSVR.best_estimator_\n",
    "# print('Melhores params: ', gridSVR.best_params_)\n",
    "# pickle.dump(X,open('XSVR.p','wb'))\n",
    "# pickle.dump(gridSVR,open('GridSVR.p','wb'))\n",
    "# print(bestSVR.score(DocsTrain,ytrain))\n",
    "# print(bestSVR.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pickle.load(open('XSVR.p','rb'))\n",
    "# DocsTrain, DocsTest, ytrain, ytest = train_test_split(X,y,test_size=0.50,shuffle=False,random_state=18)\n",
    "# grid1 = pickle.load(open('GridSVR.p','rb'))\n",
    "# best1 = grid1.best_estimator_\n",
    "# print(grid1.best_params_)\n",
    "# print(best1.score(DocsTrain,ytrain))\n",
    "# # print('COMO É QUE ISTO SOBRE APRENDEU')\n",
    "# print(best1.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
=======
   "execution_count": 137,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridSearch = pickle.load(open('gridSearch.p','rb'))\n",
    "# bestLogReg = gridSearch.best_estimator_\n",
    "# print(bestLo50*gReg.score(DocsTrain,ytrain))\n",
    "# print(bestLogReg.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 138,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest_grid = {\n",
    "#     'n_estimators': [100,200],         # Number of trees\n",
    "#     'max_depth': [20,30],         # Maximum depth of each tree\n",
    "#     'max_features': ['log2','sqrt'],        # Number of features to consider at each split\n",
    "#     'min_samples_split': [2],         # Minimum samples needed to split a node\n",
    "#     'min_samples_leaf': [1]   # Minimum samples needed to be at a leaf node\n",
    "# }\n",
    "\n",
    "# forest = RandomForestClassifier(random_state=1)\n",
    "# gridForest = GridSearchCV(forest,param_grid=forest_grid,cv=5)\n",
    "# gridForest.fit(DocsTrain,ytrain)\n",
    "# bestForest = gridForest.best_estimator_\n",
    "# print('Best params: ', gridForest.best_params_)\n",
    "\n",
    "# print(bestForest.score(DocsTrain,ytrain))\n",
    "# print(bestForest.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 139,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'C': [0.0001, 0.001, 0.01, 0.1, 1, 10,100,1000],\n",
    "#     'max_iter': [1000],\n",
    "#     'tol': [1e-1,1e-2,1e-3,1e-4, 1e-5, 1e-6],\n",
    "#     'solver': ['lbfgs', 'saga']\n",
    "# }\n",
    "# gridSearch = GridSearchCV(LogisticRegression(penalty='l2'),param_grid,cv=5)\n",
    "# gridSearch.fit(DocsTrain,ytrain)\n",
    "# bestLogReg = gridSearch.best_params_\n",
    "\n",
    "# dl = LogisticRegression(penalty='l2',max_iter=1000,C=1,tol=1e-3)\n",
    "# dl.fit(DocsTrain,ytrain)\n",
    "# print(bestLogReg.score(DocsTrain,ytrain))\n",
    "# print(bestLogReg.score(DocsTest,ytest))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 140,
>>>>>>> parent of 20cfeb8b (TP2)
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestLogReg = gridSearch.best_estimator_\n",
    "# print(bestLogReg.score(DocsTrain,ytrain))\n",
    "# print(bestLogReg.score(DocsTest,ytest))\n",
    "# pickle.dump(gridSearch,open('gridSearch.p','wb'))\n",
    "# pickle.dump(bestLogReg,open('bestLogReg.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
